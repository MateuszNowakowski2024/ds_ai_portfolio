{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to My Portfolio","text":""},{"location":"#about-me","title":"About Me","text":"<p>Hello! My name is Mateusz Nowakowski, and I am a passionate data scientist and AI enthusiast. This portfolio showcases my work in data science and artificial intelligence, where I apply cutting-edge techniques to solve real-world problems.</p> <p>Get in Touch</p>"},{"location":"#projects-overview","title":"Projects Overview","text":""},{"location":"#current-projects","title":"Current Projects","text":""},{"location":"#prompt-master","title":"Prompt Master","text":"<p>Transforming AI Interactions PromptMaster is a tool designed to simplify how users create and manage prompts for Large Language Models (LLMs). It aims to make interactions with AI clearer and more effective. Key features include easy input via text or voice, smart editing, organized project management, session management, and output modification. This tool is essential for professionals, educators, and creatives looking to enhance their AI interactions.</p>"},{"location":"#lily-20","title":"Lily 2.0","text":"<p>Revolutionizing Coloring Experiences for Kids Lily 2.0 is the next-generation version of my coloring book app, Lily 1.0. It integrates advanced AI and voice command features, making it more interactive and user-friendly for children and their guardians. Key features include voice-activated interaction, AI-driven coloring, interactive coloring, and a user-friendly design. Lily 2.0 transforms traditional coloring books into an engaging, voice-controlled experience powered by AI.</p>"},{"location":"#previous-projects","title":"Previous Projects","text":""},{"location":"#lily-10","title":"Lily 1.0","text":"<p>Advanced Coloring Book Generator Lily 1.0 is a cutting-edge coloring book generator designed for children. It blends a user-friendly interface with sophisticated backend technologies to inspire creativity and provide endless fun. Key features include an intuitive interface, interactive chat assistant, and three generation options: random coloring page, description-based coloring page, and photo to coloring page. The app utilizes advanced AI integration, machine learning, and image processing to deliver a seamless experience.</p>"},{"location":"#running-time-estimator","title":"Running Time Estimator","text":"<p>Half Marathon Time Predictor App This app predicts half marathon completion times based on user inputs, incorporating BMI-based time offsetting for refined accuracy. It offers real-time monitoring and logging, cloud storage, and user assistance through AI mode. The app leverages technologies like Jupyter Lab, Pandas, PyCaret, AWS S3, and Langfuse for data analysis, cloud services, and monitoring.</p>"},{"location":"#iris-eda","title":"Iris EDA","text":"<p>Exploratory Data Analysis on the Iris Dataset This project involves performing an exploratory data analysis (EDA) on the famous Iris dataset. The analysis includes data visualization, statistical analysis, and machine learning techniques to uncover patterns and insights within the data. Key features include interactive visualizations, detailed statistical summaries, and predictive modeling using Scikit-learn.</p>"},{"location":"#titanic-eda","title":"Titanic EDA","text":"<p>Exploratory Data Analysis on the Titanic Dataset This project focuses on conducting an exploratory data analysis (EDA) on the Titanic dataset. The analysis aims to understand the factors that influenced passenger survival rates. Key features include data cleaning, feature engineering, visualization of survival statistics, and predictive modeling using machine learning algorithms.</p>"},{"location":"#technologies-and-skills-utilized","title":"Technologies and Skills Utilized","text":"<ul> <li>Programming Languages: Python</li> <li>Machine Learning &amp; AI: PyCaret, Scikit-learn, GPT-4o-mini, DALL-E 3, Whisper 1, PyTorch</li> <li>Data Analysis &amp; Manipulation: Jupyter Lab, Pandas, Matplotlib, Seaborn, Plotly, SciPy</li> <li>Cloud Services: AWS S3, Qdrant, Langfuse, Streamlit</li> <li>Image Processing: Scikit-image, PIL, KMeans clustering</li> <li>Development &amp; Version Control: GitHub</li> <li>Real-Time Monitoring: Langfuse</li> <li>Web Development: HTML, CSS, Streamlit</li> </ul> <p>This portfolio highlights my ability to apply advanced data science and AI techniques to create innovative solutions. From enhancing AI interactions to developing engaging educational tools, my projects demonstrate a commitment to leveraging technology for impactful results.</p> <p>Get in Touch</p>"},{"location":"contact/","title":"Get in Touch","text":"<p>I\u2019m always excited to connect with fellow data enthusiasts, discuss potential collaborations, or explore new opportunities in Machine Learning, AI, and Data Modeling. Let\u2019s work together to drive innovation and make data-driven decisions!</p>"},{"location":"contact/#email-matnow2030gmailcom","title":"\ud83d\udce7 Email: mat.now2030@gmail.com","text":""},{"location":"contact/#linkedin","title":"\ud83d\udd17 LinkedIn","text":""},{"location":"contact/#github","title":"\ud83d\udc31 GitHub","text":""},{"location":"contact/#portfolio-this-website","title":"\ud83c\udf10 Portfolio - this website","text":"<p>Feel free to reach out via any of the above channels. I look forward to connecting with you!</p> <p>or simply leave a comment below:</p>"},{"location":"blog/","title":"My Blog Project","text":"<p>Welcome to my blog! Here you'll find a blend of AI-generated and personally written content, focusing on AI, Data Science, Python Programming, Data Visualization, and more. I'll also share my journey of fully automating my social media presence, starting here and expanding to other platforms. It's going to be an exciting adventure, so stay tuned! </p> <p>If you find my content helpful or use this information in your projects, please consider showing your support by:</p> <ul> <li> <p>Starring my repository on GitHub</p> </li> <li> <p>Leaving a comment on my portfolio's home page</p> </li> </ul> <p>Your feedback helps me create better content and motivates me to share more!</p>"},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/","title":"How to Enable Comments in MkDocs Portfolio","text":"<p>This guide explains how to enable comments in your MkDocs site. I created it by analyzing the MkDocs documentation and using AI assistance to create clear, step-by-step instructions.</p>","tags":["Manual","Guide"]},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/#prompt-gpt-o1","title":"Prompt GPT-o1","text":"<p>Context: MkDocs documentation</p> <p>Problem: Adding comments functionality to MkDocs portfolio</p> <p>Objective: Create a step-by-step guide to enable comments in a MkDocs website using Giscus</p> <p>Below is a detailed walkthrough that will help you integrate Giscus comments into your MkDocs site using the Material for MkDocs theme. Follow these instructions carefully to enable interactive comments on your documentation pages.</p>","tags":["Manual","Guide"]},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/#repsonse","title":"Repsonse:","text":"","tags":["Manual","Guide"]},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/#prerequisites","title":"Prerequisites","text":"<ul> <li>You already have a MkDocs project set up with the Material for MkDocs theme.</li> <li>You have a GitHub account and a repository where you\u2019d like to host the discussions for your comments.</li> </ul>","tags":["Manual","Guide"]},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/#steps","title":"Steps","text":"<ol> <li> <p>Install Material for MkDocs (if not already)</p> <ul> <li> <p>If you haven\u2019t installed Material for MkDocs yet, do so by running:</p> <p><code>pip install mkdocs-material</code></p> </li> <li> <p>Ensure it\u2019s activated in your <code>mkdocs.yml</code> config:</p> <p><code>theme:</code> </p> <p><code>name: material</code></p> </li> </ul> </li> <li> <p>Set up a GitHub repository for discussions</p> <ul> <li>Decide which GitHub repository will host the discussions for your comments. This can be the same repo that holds your documentation source, or a completely separate repo.</li> <li>Enable GitHub Discussions on that repository if you haven\u2019t already. Go to the repo\u2019s \"Settings\" \u2192 \"General\" tab, scroll down to \"Features,\" and enable Discussions.</li> <li> <p>Install the Giscus GitHub App</p> </li> <li> <p>Go to https://giscus.app/ and follow the instructions to install the Giscus GitHub App.</p> </li> <li>Grant the app permission to the repository you\u2019ve chosen for discussions.</li> <li>This app will handle the backend for your comments.</li> <li> <p>Generate your Giscus snippet</p> </li> <li> <p>While still on https://giscus.app/, follow their configuration tool:</p> <ul> <li>Choose the repository and discussion category you want to use.</li> <li>Set the \"Discussion Mapping\" to something appropriate, for example <code>pathname</code>.</li> <li>Select your preferred theme (you can leave it as <code>light</code> for now; Material for MkDocs will handle theme switching).</li> </ul> </li> <li>The tool will generate a <code>&lt;script&gt;</code> snippet. Copy this entire snippet.</li> <li> <p>Create the <code>comments.html</code> partial override</p> </li> <li> <p>In your MkDocs project, create a folder named <code>overrides</code> (if it does not already exist):</p> <p><code>mkdir overrides</code></p> </li> <li> <p>Inside <code>overrides</code>, create a folder structure matching the theme\u2019s partial structure:</p> <p><code>mkdir -p overrides/partials</code></p> </li> <li> <p>Create (or edit) <code>comments.html</code> inside <code>overrides/partials/</code>:</p> </li> </ul> </li> </ol> <pre><code>`&lt;!-- overrides/partials/comments.html --&gt;`\n`{% if page.meta.comments %}`\n  `&lt;h2 id=\"__comments\"&gt;{{ lang.t(\"meta.comments\") }}&lt;/h2&gt;`\n\n  `&lt;!-- Paste your Giscus snippet directly below this line --&gt;`\n\n  `&lt;!-- Synchronize Giscus theme with palette --&gt;`\n  `&lt;script&gt;`\n    `var giscus = document.querySelector(\"script[src*=giscus]\")`\n\n    `// Set palette on initial load`\n    `var palette = __md_get(\"__palette\")`\n    `if (palette &amp;&amp; typeof palette.color === \"object\") {`\n      `var theme = palette.color.scheme === \"slate\"`\n        `? \"transparent_dark\"`\n        `: \"light\"`\n      `giscus.setAttribute(\"data-theme\", theme)` \n    `}`\n\n    `// Register event handlers after document loaded`\n    `document.addEventListener(\"DOMContentLoaded\", function() {`\n      `var ref = document.querySelector(\"[data-md-component=palette]\")`\n      `ref.addEventListener(\"change\", function() {`\n        `var palette = __md_get(\"__palette\")`\n        `if (palette &amp;&amp; typeof palette.color === \"object\") {`\n          `var theme = palette.color.scheme === \"slate\"`\n            `? \"transparent_dark\"`\n            `: \"light\"`\n          `var frame = document.querySelector(\".giscus-frame\")`\n          `frame.contentWindow.postMessage(`\n            `{ giscus: { setConfig: { theme } } },`\n            `\"https://giscus.app\"`\n          `)`\n        `}`\n      `})`\n    `})`\n  `&lt;/script&gt;`\n`{% endif %}`\n`\n</code></pre> <ul> <li>Important: Replace the <code>&lt;!-- Paste your Giscus snippet here --&gt;</code> comment with the actual <code>&lt;script&gt;</code> code you copied from Giscus.</li> </ul> <p>Your final <code>comments.html</code> might look like this (simplified example):</p> <pre><code>    ``{% if page.meta.comments %}`\n  `&lt;h2 id=\"__comments\"&gt;{{ lang.t(\"meta.comments\") }}&lt;/h2&gt;`\n  `&lt;script`\n    `src=\"https://giscus.app/client.js\"`\n    `data-repo=\"username/repo\"`\n    `data-repo-id=\"...\"`\n    `data-category=\"...\"`\n    `data-category-id=\"...\"`\n    `data-mapping=\"pathname\"`\n    `data-reactions-enabled=\"1\"`\n    `data-emit-metadata=\"1\"`\n    `data-theme=\"light\"`\n    `data-lang=\"en\"`\n    `crossorigin=\"anonymous\"`\n    `async&gt;`\n  `&lt;/script&gt;`\n\n  `&lt;script&gt;`\n    `// Theme synchronization code (from the docs)`\n    `var giscus = document.querySelector(\"script[src*=giscus]\")`\n    `var palette = __md_get(\"__palette\")`\n    `if (palette &amp;&amp; typeof palette.color === \"object\") {`\n      `var theme = palette.color.scheme === \"slate\"`\n        `? \"transparent_dark\"`\n        `: \"light\"`\n      `giscus.setAttribute(\"data-theme\", theme)` \n    `}`\n    `document.addEventListener(\"DOMContentLoaded\", function() {`\n      `var ref = document.querySelector(\"[data-md-component=palette]\")`\n      `ref.addEventListener(\"change\", function() {`\n        `var palette = __md_get(\"__palette\")`\n        `if (palette &amp;&amp; typeof palette.color === \"object\") {`\n          `var theme = palette.color.scheme === \"slate\"`\n            `? \"transparent_dark\"`\n            `: \"light\"`\n          `var frame = document.querySelector(\".giscus-frame\")`\n          `frame.contentWindow.postMessage(`\n            `{ giscus: { setConfig: { theme } } },`\n            `\"https://giscus.app\"`\n          `)`\n        `}`\n      `})`\n    `})`\n  `&lt;/script&gt;`\n`{% endif %}`\n`\n</code></pre> <ol> <li> <p>Point MkDocs to the overrides directory</p> <ul> <li> <p>In your <code>mkdocs.yml</code>, add or confirm the following:</p> <p><code>theme:</code> <code>name: material</code> <code>custom_dir: overrides</code></p> </li> <li> <p>This tells MkDocs to use the <code>overrides</code> directory to replace default theme partials.</p> </li> <li> <p>Enable comments on a page</p> </li> <li> <p>Open a Markdown page file where you want comments enabled, e.g. <code>docs/index.md</code>.</p> </li> <li> <p>At the top of the page, add:</p> <p><code>---</code> <code>comments: true</code> <code>---</code></p> </li> <li> <p>This front matter signals to the theme that it should display the comment section on this page.</p> </li> <li> <p>Build and serve your site</p> </li> <li> <p>Run <code>mkdocs serve</code> to start the development server:</p> <p><code>mkdocs serve</code></p> </li> <li> <p>Open http://127.0.0.1:8000 in your browser.</p> </li> <li>Navigate to the page where you enabled comments. You should see the Giscus comment widget.</li> <li> <p>Test, commit, and deploy</p> </li> <li> <p>Once you verify that comments are working locally, commit your changes.</p> </li> <li>Deploy your MkDocs site the way you usually do (e.g., GitHub Pages, Netlify, etc.).</li> <li>After deployment, visitors to those pages will be able to view and add comments.</li> </ul> </li> </ol>","tags":["Manual","Guide"]},{"location":"blog/2024/12/12/how-to-enable-comments-in-mkdocs-portfolio/#thats-it","title":"That\u2019s it!","text":"<p>By following these simple steps, you\u2019ve integrated Giscus comments into your MkDocs Material site. Now you have an interactive comment system that uses GitHub Discussions as a backend\u2014completely free and open source.</p>","tags":["Manual","Guide"]},{"location":"blog/2024/12/10/my-first-blog-post/","title":"My First Blog Post","text":"<p>I was going to start a blog but wasn't sure where to begin. Then I had an idea: why not combine my data science skills to create an AI-automated blog? During the planning process, I realized this journey itself would make interesting content to share with others.</p> <p>The first few posts will document this exciting process: - Adding a comment section to my portfolio - Creating the blog infrastructure - Developing an AI system to assist with content creation - Implementing social media automation</p> <p>My goal is to help you create your own automated blog and social media presence. I'll keep everything simple and beginner-friendly, breaking down complex concepts into easy-to-follow steps.</p> <p>This blog will feature a mix of AI-generated and personally written content, focusing on: - Data Science - Artificial Intelligence - Python Programming - Data Visualization</p> <p>You'll find practical tutorials, guides, and insights into the latest developments in these fields. Join me on this journey of exploring how AI can transform content creation while learning valuable technical skills along the way.</p>","tags":["Introduction","Welcome"]},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/","title":"Revolutionizing Natural Language Processing: The Rise of Transformers","text":""},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/#introduction","title":"Introduction","text":"<p>Hey there, fellow data enthusiasts! Today, we\u2019re diving into one of the most exciting advancements in the world of Data Science and AI: the Transformer model. If you\u2019ve ever used a virtual assistant like Siri or Alexa, or even chatted with a chatbot, you\u2019ve likely benefited from the magic of Transformers. This architecture has truly transformed how we handle Natural Language Processing (NLP).</p>"},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/#what-are-transformers","title":"What Are Transformers?","text":"<p>Originally introduced in a groundbreaking paper titled \"Attention Is All You Need\" by Vaswani et al. in 2017, Transformers shifted the paradigm of NLP. Unlike traditional models that processed text sequentially, Transformers utilize a mechanism called \u201cself-attention.\u201d This allows them to weigh the importance of different words in a sentence relative to each other, making it easier to understand context and meaning.</p> <p>For instance, in the sentence \"The cat sat on the mat,\" a traditional model might struggle to connect \"cat\" and \"mat.\" In contrast, a Transformer model can easily understand the relationships between words, leading to better comprehension and generation of text.</p>"},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/#the-impact-of-transformers","title":"The Impact of Transformers","text":"<p>Since their inception, Transformers have paved the way for a slew of powerful models, such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). These models have smashed records in various NLP tasks, from sentiment analysis to machine translation.</p> <p>Recently, researchers have been focusing on making Transformers more efficient. Techniques like distillation and pruning are being used to reduce their size without sacrificing performance. This means faster processing and less resource consumption, making AI more accessible to everyone.</p>"},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/#conclusion","title":"Conclusion","text":"<p>In a nutshell, the Transformer model has revolutionized how we approach language tasks in AI. With its ability to understand context and generate coherent text, it\u2019s no wonder that Transformers are at the heart of many modern NLP applications. As we continue to refine and improve these models, the potential for even more innovative applications is limitless. So, keep your eyes peeled; the future of AI is looking brighter than ever! </p>"},{"location":"blog/2024/12/10/revolutionizing-natural-language-processing-the-rise-of-transformers/#references","title":"References","text":"<ul> <li>Vaswani, A., et al. (2017). \"Attention Is All You Need.\" arXiv preprint arXiv:1706.03762.</li> <li>Devlin, J., et al. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" arXiv preprint arXiv:1810.04805.</li> </ul>"},{"location":"estimator/","title":"Half Marathon Time Predictor App","text":"<p> Link to the app</p>"},{"location":"estimator/#overview","title":"Overview","text":"<p>Introducing the Half Marathon Time Predictor, an innovative application I developed to accurately estimate your half marathon completion time by leveraging advanced machine learning techniques. Whether you're a seasoned runner or just starting your fitness journey, my app seamlessly integrates personalized data to provide reliable time predictions, helping you set and achieve your running goals with confidence.</p> Home Screen Data Entry Prediction Results"},{"location":"estimator/#key-features","title":"Key Features","text":""},{"location":"estimator/#dual-operation-modes","title":"Dual Operation Modes:","text":"<ul> <li>Classic Mode: Manually input your personal data, including gender, age, average pace per kilometer, and BMI.</li> <li>AI-Assisted Mode: Engage in a conversational interface where the chatbot intelligently gathers your information, ensuring a smooth and interactive user experience.</li> </ul>"},{"location":"estimator/#comprehensive-data-handling","title":"Comprehensive Data Handling:","text":"<ul> <li>BMI Calculation: Automatically computes your BMI based on provided weight and height if not directly supplied.</li> <li>Pace Estimation: If your running pace isn't specified, the app intelligently substitutes it with the median pace derived from extensive marathon datasets segmented by age and gender.</li> </ul>"},{"location":"estimator/#consistent-machine-learning-model","title":"Consistent Machine Learning Model:","text":"<p>Both modes utilize the same robust machine learning model hosted in the cloud, ensuring uniform and dependable time predictions regardless of the input method.</p>"},{"location":"estimator/#advanced-time-adjustment","title":"Advanced Time Adjustment:","text":"<p>Incorporates BMI-based time offsetting to refine accuracy beyond standard modeling techniques like PyCaret.</p>"},{"location":"estimator/#real-time-monitoring-and-logging","title":"Real-Time Monitoring and Logging:","text":"<p>Langfuse Integration: Provides continuous monitoring of app performance and user interactions. Cloud Storage: Securely stores all user conversations and input data in the cloud, ensuring data integrity and accessibility. User Assistance:</p> <p>The AI mode offers contextual help, guiding users through the data entry process while requiring at least a minimal pace input (e.g., 1 km) to function effectively. Technologies and Skills Utilized</p>"},{"location":"estimator/#data-analysis-modeling","title":"Data Analysis &amp; Modeling:","text":"<ul> <li>Jupyter Lab: Utilized for developing and testing the machine learning models.</li> <li>Pandas: Employed for efficient data manipulation and analysis.</li> <li>Machine Learning (Regression): Implemented to predict half marathon completion times based on user inputs.</li> <li>PyCaret: Leveraged for streamlined machine learning workflows and model optimization.</li> </ul>"},{"location":"estimator/#cloud-services-deployment","title":"Cloud Services &amp; Deployment:","text":"<ul> <li>AWS S3: Facilitated secure uploading and storage of datasets and user inputs.</li> </ul>"},{"location":"estimator/#monitoring-maintenance","title":"Monitoring &amp; Maintenance:","text":"<ul> <li>Langfuse: Integrated for real-time monitoring of application performance and user interactions.</li> </ul>"},{"location":"estimator/#development-version-control","title":"Development &amp; Version Control:","text":"<ul> <li>GitHub: Managed source code, collaboration, and version control to ensure seamless development and deployment processes.</li> </ul>"},{"location":"estimator/#why-choose-my-app","title":"Why Choose My App?","text":"<ul> <li>Precision: Combines multiple personal metrics with sophisticated machine learning algorithms to deliver highly accurate predictions.</li> <li>Flexibility: Offers both manual and AI-driven data input methods to cater to diverse user preferences.</li> <li>Reliability: Ensures consistent results by utilizing a unified machine learning model across all operation modes.</li> <li>Security: Maintains the highest standards of data security with cloud storage and monitored interactions.</li> <li>User-Friendly: Designed with intuitive interfaces and helpful guides to enhance user experience.</li> </ul> <p>Embark on your half marathon journey with confidence. Let my Half Marathon Time Predictor App provide the insights you need to train smarter and run stronger.</p> <p> Link to the app</p>"},{"location":"estimator/#screenshots","title":"Screenshots","text":"<p>Here are some screenshots showcasing the app's interface and features:</p> <p> Home Screen</p> <p> Data Entry</p> <p> Prediction Results</p>"},{"location":"iris/","title":"Explanatory Data Analysis Iris Dataset","text":""},{"location":"iris/#introduction","title":"Introduction","text":"<p>In this project, I will perform an Exploratory Data Analysis (EDA) on the Iris dataset. The Iris dataset is a classic dataset used in machine learning and statistics, often used for testing purposes. It contains measurements of sepal length, sepal width, petal length, and petal width for three different species of Iris flowers: Iris-setosa, Iris-versicolor, and Iris-virginica. </p> <p> Link to the notebook</p> <p> </p>"},{"location":"lily_1_0/","title":"Lily-1.0 Advanced Coloring Book Generator!","text":"Lily-1.0 App"},{"location":"lily_1_0/#overview","title":"Overview","text":"<p>Lily-1.0 is a cutting-edge coloring book generator designed for children, seamlessly blending a user-friendly interface with sophisticated backend technologies to inspire creativity and provide endless fun.</p>"},{"location":"lily_1_0/#key-features","title":"Key Features","text":""},{"location":"lily_1_0/#intuitive-interface","title":"Intuitive Interface","text":"<p>The main layout features a single \u201cReset Session\u201d button, allowing users to effortlessly start fresh by clearing chat history and session states.</p>"},{"location":"lily_1_0/#interactive-chat-assistant","title":"Interactive Chat Assistant","text":"<p>Engage with Lily-1.0 through a chat interface powered by GPT-4o-mini. The assistant guides users through three creative options to generate personalized coloring pages. </p>"},{"location":"lily_1_0/#three-generation-options","title":"Three Generation Options","text":""},{"location":"lily_1_0/#random-coloring-page","title":"Random Coloring Page","text":"<p>Instantly generate a random coloring page. Lily creates a unique prompt, and upon approval, DALL-E 3 generates a downloadable image.</p>"},{"location":"lily_1_0/#description-based-coloring-page","title":"Description-Based Coloring Page","text":"<p>Create a custom coloring page based on your own descriptions. Whether you provide a detailed description or just a few keywords, Lily refines the input and uses DALL-E 3 to produce a personalized image.</p>"},{"location":"lily_1_0/#photo-to-coloring-page","title":"Photo to Coloring Page","text":"<p>Transform your own photos into coloring pages. Upload a photo, adjust parameters with intuitive sliders, and click \"Convert Photo\" to receive a downloadable coloring version. Lily assists by explaining the settings and their effects. </p>"},{"location":"lily_1_0/#technical-highlights","title":"Technical Highlights","text":""},{"location":"lily_1_0/#advanced-ai-integration","title":"Advanced AI Integration","text":"<p>Utilizes GPT-4o-mini for intelligent and engaging chat interactions, and DALL-E 3 for high-quality image generation.</p>"},{"location":"lily_1_0/#machine-learning-image-processing","title":"Machine Learning &amp; Image Processing","text":"<p>Implements Scikit-learn, Scikit-image, KMeans clustering, and PIL to efficiently convert photos into coloring pages without relying on resource-intensive libraries like TensorFlow. This results in a streamlined process reduced from 500 to approximately 80 lines of code.</p>"},{"location":"lily_1_0/#optimized-performance","title":"Optimized Performance","text":"<p>Automatically resizes uploaded images to \u22641.5 MB and 1024x1024 resolution using PIL, ensuring quick processing and minimal loading times.</p>"},{"location":"lily_1_0/#efficient-image-clustering","title":"Efficient Image Clustering","text":"<p>Uses KMeans clustering to simplify images into 2-20 color clusters, outlining boundaries with black lines to create clear and engaging coloring pages.</p>"},{"location":"lily_1_0/#user-friendly-design","title":"User-Friendly Design","text":"<p>Simple navigation through easy commands such as \u201chi\u201d to start and \u201cmain options\u201d to return to the menu, making the app accessible for both children and adults.</p>"},{"location":"lily_1_0/#advanced-functionality","title":"Advanced Functionality","text":"<p>Combines machine learning techniques like image clustering and cartoonization with persona-adopted chat assistance, offering a rich and interactive user experience.</p>"},{"location":"lily_1_0/#why-choose-lily-10","title":"Why Choose Lily-1.0?","text":"<p>Lily-1.0 Advanced Coloring Book Generator stands out by offering a sleek and minimalistic interface while leveraging state-of-the-art technologies in the backend. This combination ensures that users enjoy a smooth and engaging experience, whether they\u2019re generating random designs, customizing based on their descriptions, or transforming personal photos into delightful coloring pages. Lily-1.0 is not just a coloring book generator; it\u2019s a gateway to creativity powered by the latest advancements in AI and machine learning.</p> Lily-1.0 App"},{"location":"lily_1_0/#gallery","title":"Gallery","text":"<p>Check out the gallery to see more images created by Lily-1.0.</p>"},{"location":"lily_2_0/","title":"Project Spotlight: Lily 2.0","text":""},{"location":"lily_2_0/#revolutionizing-coloring-experiences-for-kids","title":"Revolutionizing Coloring Experiences for Kids","text":"<p>I am excited to present Lily 2.0, the next-generation version of my popular coloring book app, Lily 1.0. Lily 2.0 takes the coloring experience to a completely new level by integrating advanced AI and voice command features, making it more interactive and user-friendly for children and their guardians.</p>"},{"location":"lily_2_0/#project-overview","title":"Project Overview","text":"<p>Lily 2.0 is designed to allow users to generate unique coloring books and color them within the app using simple voice commands. The app remains incredibly easy to use, ensuring that children can enjoy creating and coloring without any technical difficulties. All the complex AI and machine learning processes, powered by technologies like Scikit-learn, Pillow, and PyTorch, work seamlessly in the background, providing a smooth and engaging experience.</p>"},{"location":"lily_2_0/#key-features","title":"Key Features","text":""},{"location":"lily_2_0/#voice-activated-interaction","title":"Voice-Activated Interaction","text":"<ul> <li>Easy Commands: Users can create and color their coloring books by speaking to Lily, the friendly chatbot.</li> <li>Voice to Text: Voice recordings are transcribed into text using Whisper 1, which Lily uses to generate and modify coloring pages.</li> </ul>"},{"location":"lily_2_0/#ai-driven-coloring","title":"AI-Driven Coloring","text":"<ul> <li>Smart Generation: Generate personalized coloring books based on user descriptions and photos.</li> <li>Element Segmentation: An advanced algorithm, utilizing PyTorch, processes and segments the outline images into individual elements with assigned names, allowing precise coloring.</li> </ul>"},{"location":"lily_2_0/#interactive-coloring","title":"Interactive Coloring","text":"<ul> <li>Select and Color: Users can choose specific elements from a list and select colors, which are then applied to the chosen parts of the image.</li> <li>Real-Time Feedback: See colors applied instantly, making the coloring process fun and engaging.</li> </ul>"},{"location":"lily_2_0/#user-friendly-design","title":"User-Friendly Design","text":"<ul> <li>Simple Interface: Designed for children and their guardians, ensuring ease of use with a playful and intuitive layout.</li> <li>Friendly Chatbot: Lily guides users through the process with cheerful interactions, making the experience enjoyable.</li> </ul>"},{"location":"lily_2_0/#why-lily-20","title":"Why Lily 2.0?","text":"<p>Lily 2.0 transforms a traditional coloring book into an interactive, voice-controlled experience powered by AI. By making the app more dynamic and engaging, it not only entertains but also fosters creativity and learning in children. This innovative approach sets Lily 2.0 apart, making it a standout tool in educational and recreational apps for kids.</p>"},{"location":"lily_2_0/#current-status-and-invitation","title":"Current Status and Invitation","text":"<p>Lily 2.0 is currently in the early research stage. I am dedicated to developing a high-quality, cutting-edge app that will redefine how children interact with coloring books. I am seeking investors who are passionate about educational technology and innovation to support this exciting project.</p> <p>Additionally, I invite AI and data science professionals who are interested in joining this transformative project to reach out and collaborate. Together, we can bring Lily 2.0 to life and create a magical coloring experience for children everywhere.</p>"},{"location":"prompt_master/","title":"Project Spotlight: PromptMaster","text":""},{"location":"prompt_master/#transforming-ai-interactions","title":"Transforming AI Interactions","text":"<p>I am excited to introduce PromptMaster, a tool I am developing to simplify how users create and manage prompts for Large Language Models (LLMs). PromptMaster aims to make interactions with AI clearer and more effective.</p>"},{"location":"prompt_master/#key-features","title":"Key Features:","text":""},{"location":"prompt_master/#easy-input","title":"Easy Input","text":"<ul> <li>Text or Voice: Enter prompts by typing or recording voice notes, which are transcribed automatically.</li> <li>Instant Display: See your input immediately in the display area for easy review.</li> </ul>"},{"location":"prompt_master/#smart-editing","title":"Smart Editing","text":"<ul> <li>Edit Button: Click to have your prompt refined for clarity and effectiveness using the \"Prompt Master\" model.</li> <li>Additional Tools: Access extra prompt techniques from the sidebar to enhance your prompts further.</li> </ul>"},{"location":"prompt_master/#project-management","title":"Project Management","text":"<ul> <li>Organized Folders: Create projects that generate folders with \"input\" and \"output\" subfolders.</li> <li>Save Easily: Save your original and edited prompts in their respective folders.</li> </ul>"},{"location":"prompt_master/#session-management","title":"Session Management","text":"<ul> <li>Save and Load: Save your entire session, including all files and folders, and load them later to continue your work.</li> </ul>"},{"location":"prompt_master/#output-modification","title":"Output Modification","text":"<ul> <li>Editing Options: Use tools to simplify language, specify formats, add context, and more.</li> <li>Prompt Browser: Browse and reuse previously saved prompts.</li> </ul>"},{"location":"prompt_master/#why-promptmaster","title":"Why PromptMaster?","text":"<p>Clear and effective prompts are essential for getting the best results from AI. PromptMaster helps users create and manage prompts easily, improving their interactions with LLMs. Whether you're a professional, educator, or creative, this tool will help you get more out of AI.</p>"},{"location":"prompt_master/#coming-soon","title":"Coming Soon:","text":"<p>PromptMaster is still under development. I am dedicated to building a user-friendly tool that meets your needs. Stay tuned for the official launch!</p>"},{"location":"prompt_master/#get-involved","title":"Get Involved:","text":"<p>I am looking for investors to support PromptMaster. Your investment will help bring this tool to users, enhancing how they interact with AI.</p>"},{"location":"titanic/","title":"Titanic Disaster Analysis","text":""},{"location":"titanic/#a-data-driven-investigation-of-the-1912-maritime-tragedy","title":"A Data-Driven Investigation of the 1912 Maritime Tragedy","text":"<p>This analysis explores the passenger data from the RMS Titanic disaster, examining survival patterns and social dynamics aboard history's most famous shipwreck. Through statistical analysis and data visualization, we'll investigate:</p> <ul> <li>Passenger demographics and survival rates</li> <li>The impact of social class on survival</li> <li>Gender and age-based survival patterns</li> <li>Family dynamics during the disaster</li> <li>Lifeboat allocation and evacuation patterns</li> </ul> <p>The dataset contains information on 1,309 passengers, including details about their age, gender, ticket class, fare paid, and survival status. This analysis aims to uncover the human stories behind the numbers and understand the factors that influenced survival on that fateful night of April 15, 1912.</p> <p>Let's begin our journey through the data...</p> <p> Link to the notebook</p> <p> </p>"},{"location":"blog/archive/2024/","title":"2024","text":""}]}